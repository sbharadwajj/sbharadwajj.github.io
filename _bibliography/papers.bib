---
---

@article{bharadwaj2023flare,
  bibtex_show={true},
  title = {{FLARE}: Fast learning of Animatable and Relightable Mesh Avatars},
  author = {Bharadwaj, Shrisha and Zheng, Yufeng and Hilliges, Otmar and Black, Michael J. and Abrevaya, Victoria Fernandez},
  journal = {arXiv preprint arXiv:2310.17519},
  year = {2023},
  preview={thumbnail_flare.gif}
}

@INPROCEEDINGS {9093342,
author = {D. Mandal* and S. Bharadwaj* and S. Biswas},
booktitle = {2020 IEEE Winter Conference on Applications of Computer Vision (WACV)},
title = {A Novel Self-Supervised Re-labeling Approach for Training with Noisy Labels},
year = {2020},
volume = {},
issn = {},
pages = {1370-1379},
abstract = {The major driving force behind the immense success of deep learning models is the availability of large datasets along with their clean labels. This is very difficult to obtain and thus has motivated research on training deep neural networks in the presence of label noise. In this work, we build upon the seminal work in this area, Co-teaching and propose a simple, yet efficient approach termed mCT-S2R (modified co-teaching with self-supervision and relabeling) for this task. Firstly, to deal with significant amount of noise in the labels, we propose to use self-supervision to generate robust features without using any labels. Furthermore, using a parallel network architecture, an estimate of the clean labeled portion of the data is obtained. Finally, using this data, a portion of the estimated noisy labeled portion is re-labeled, before resuming the network training with the augmented data. Extensive experiments on three standard datasets show the effectiveness of the proposed framework.},
keywords = {training;task analysis;noise measurement;data models;training data;computational modeling;robustness},
doi = {10.1109/WACV45572.2020.9093342},
url = {https://doi.ieeecomputersociety.org/10.1109/WACV45572.2020.9093342},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}
